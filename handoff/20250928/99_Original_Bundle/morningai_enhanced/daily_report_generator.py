#!/usr/bin/env python3
"""
æ¯æ—¥ç›£æ§å ±å‘Šç”Ÿæˆå™¨
æ ¹æ“šç›£æ§æ•¸æ“šç”Ÿæˆæ¯æ—¥ç°¡å ±ï¼Œç¬¦åˆè¦ç¯„è¦æ±‚çš„æ ¼å¼
"""

import json
import datetime
import os
import statistics
from typing import Dict, List, Optional
import requests
from dataclasses import dataclass

@dataclass
class DailyReportData:
    """æ¯æ—¥å ±å‘Šæ•¸æ“šçµæ§‹"""
    date: str
    health_status: Dict[str, Dict]
    performance_metrics: Dict
    resource_status: Dict
    alerts_summary: List[Dict]
    summary_text: str

class DailyReportGenerator:
    """æ¯æ—¥å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, data_dir: str = "data", reports_dir: str = "reports"):
        self.data_dir = data_dir
        self.reports_dir = reports_dir
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
        os.makedirs(reports_dir, exist_ok=True)
    
    def load_monitoring_data(self, date: str = None) -> Dict:
        """è¼‰å…¥æŒ‡å®šæ—¥æœŸçš„ç›£æ§æ•¸æ“š"""
        if date is None:
            date = datetime.datetime.now().strftime('%Y%m%d')
        
        filename = f"{self.data_dir}/monitoring_data_{date}.json"
        
        if not os.path.exists(filename):
            raise FileNotFoundError(f"Monitoring data file not found: {filename}")
        
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def analyze_health_status(self, health_results: List[Dict]) -> Dict[str, Dict]:
        """åˆ†æå¥åº·ç‹€æ…‹"""
        endpoints = ['/health', '/healthz', '/openapi.json']
        status_summary = {}
        
        for endpoint in endpoints:
            endpoint_results = [r for r in health_results if r['endpoint'] == endpoint]
            
            if not endpoint_results:
                status_summary[endpoint] = {
                    'status_code': 'N/A',
                    'avg_latency': 0,
                    'success_rate': 0,
                    'note': 'ç„¡æ•¸æ“š'
                }
                continue
            
            # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
            successful_results = [r for r in endpoint_results if r['success']]
            success_rate = len(successful_results) / len(endpoint_results) if endpoint_results else 0
            
            if successful_results:
                avg_latency = statistics.mean([r['latency_ms'] for r in successful_results if r['latency_ms'] > 0])
                most_common_status = statistics.mode([r['status_code'] for r in successful_results])
            else:
                avg_latency = 0
                most_common_status = 'ERROR'
            
            # ç‰¹æ®Šè™•ç† openapi.json
            note = ""
            if endpoint == '/openapi.json' and successful_results:
                # é€™è£¡å¯ä»¥æ·»åŠ æª¢æŸ¥ /auth/ å’Œ /referral/ è·¯ç”±çš„é‚è¼¯
                note = "éœ€æª¢æŸ¥ /auth/ å’Œ /referral/ è·¯ç”±"
            
            status_summary[endpoint] = {
                'status_code': most_common_status,
                'avg_latency': round(avg_latency, 2),
                'success_rate': round(success_rate * 100, 2),
                'note': note
            }
        
        return status_summary
    
    def analyze_performance_metrics(self, health_results: List[Dict]) -> Dict:
        """åˆ†ææ•ˆèƒ½æŒ‡æ¨™"""
        if not health_results:
            return {
                'p95_latency': 0,
                'error_rate': 0,
                'peak_5xx_time': 'ç„¡'
            }
        
        # è¨ˆç®— P95 å»¶é²
        successful_results = [r for r in health_results if r['success'] and r['latency_ms'] > 0]
        if successful_results:
            latencies = [r['latency_ms'] for r in successful_results]
            p95_latency = statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else max(latencies)
        else:
            p95_latency = 0
        
        # è¨ˆç®—éŒ¯èª¤ç‡
        error_count = sum(1 for r in health_results if not r['success'] or r['status_code'] >= 400)
        error_rate = (error_count / len(health_results)) * 100 if health_results else 0
        
        # æ‰¾å‡º 5xx å³°å€¼æ™‚æ®µ
        hour_5xx_counts = {}
        for result in health_results:
            if result['status_code'] >= 500:
                timestamp = datetime.datetime.fromisoformat(result['timestamp'])
                hour = timestamp.hour
                hour_5xx_counts[hour] = hour_5xx_counts.get(hour, 0) + 1
        
        if hour_5xx_counts:
            peak_hour = max(hour_5xx_counts.items(), key=lambda x: x[1])[0]
            peak_5xx_time = f"{peak_hour:02d}:00-{peak_hour+1:02d}:00"
        else:
            peak_5xx_time = "ç„¡"
        
        return {
            'p95_latency': round(p95_latency, 2),
            'error_rate': round(error_rate, 2),
            'peak_5xx_time': peak_5xx_time
        }
    
    def get_resource_status(self) -> Dict:
        """ç²å–è³‡æºç‹€æ…‹ï¼ˆæ¨¡æ“¬æ•¸æ“šï¼Œå¯¦éš›éœ€è¦é€£æ¥çœŸå¯¦æœå‹™ï¼‰"""
        return {
            'render_status': 'éœ€æ‰‹å‹•æª¢æŸ¥ Render Events',
            'db_connections': 'éœ€é€£æ¥è³‡æ–™åº«ç²å–',
            'db_errors': 'éœ€é€£æ¥è³‡æ–™åº«ç²å–'
        }
    
    def generate_summary_text(self, report_data: DailyReportData) -> str:
        """ç”Ÿæˆæ‘˜è¦æ–‡å­—ï¼ˆâ‰¦10è¡Œï¼‰"""
        lines = []
        
        # æœå‹™å¥åº·ç‹€æ…‹
        health_ok = all(status['success_rate'] > 95 for status in report_data.health_status.values())
        if health_ok:
            lines.append("âœ… æ‰€æœ‰å¥åº·æª¢æŸ¥ç«¯é»é‹è¡Œæ­£å¸¸")
        else:
            lines.append("âš ï¸ éƒ¨åˆ†å¥åº·æª¢æŸ¥ç«¯é»å­˜åœ¨å•é¡Œ")
        
        # æ•ˆèƒ½æŒ‡æ¨™
        perf = report_data.performance_metrics
        if perf['error_rate'] < 1:
            lines.append(f"âœ… éŒ¯èª¤ç‡ {perf['error_rate']:.2f}% (< 1%)")
        else:
            lines.append(f"âš ï¸ éŒ¯èª¤ç‡ {perf['error_rate']:.2f}% (â‰¥ 1%)")
        
        if perf['p95_latency'] < 500:
            lines.append(f"âœ… P95 å»¶é² {perf['p95_latency']:.2f}ms (< 500ms)")
        else:
            lines.append(f"âš ï¸ P95 å»¶é² {perf['p95_latency']:.2f}ms (â‰¥ 500ms)")
        
        # å‘Šè­¦æƒ…æ³
        if report_data.alerts_summary:
            lines.append(f"ğŸš¨ ä»Šæ—¥è§¸ç™¼ {len(report_data.alerts_summary)} å€‹å‘Šè­¦")
        else:
            lines.append("âœ… ä»Šæ—¥ç„¡å‘Šè­¦è§¸ç™¼")
        
        # 5xx å³°å€¼
        if perf['peak_5xx_time'] != "ç„¡":
            lines.append(f"ğŸ“Š 5xx éŒ¯èª¤å³°å€¼æ™‚æ®µ: {perf['peak_5xx_time']}")
        
        # è³‡æºç‹€æ…‹æé†’
        lines.append("ğŸ“‹ è«‹æª¢æŸ¥ Render Events æˆªåœ–å’Œè³‡æ–™åº«é€£ç·šç‹€æ…‹")
        
        return "\n".join(lines[:10])  # é™åˆ¶åœ¨ 10 è¡Œå…§
    
    def generate_markdown_report(self, report_data: DailyReportData) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„å ±å‘Š"""
        md_content = f"""# æ¯æ—¥ç›£æ§å ±å‘Š - {report_data.date}

## ç¸½çµ (â‰¦10 è¡Œ)

{report_data.summary_text}

## æœå‹™å¥åº·

| ç«¯é» | ç‹€æ…‹ç¢¼ | å¹³å‡å›æ‡‰æ™‚é–“ (ms) | æˆåŠŸç‡ (%) | å‚™è¨» |
|---|---|---|---|---|
"""
        
        for endpoint, status in report_data.health_status.items():
            md_content += f"| `{endpoint}` | {status['status_code']} | {status['avg_latency']} | {status['success_rate']} | {status['note']} |\n"
        
        md_content += f"""
## æ•ˆèƒ½èˆ‡éŒ¯èª¤

| æŒ‡æ¨™ | æ•¸å€¼ |
|---|---|
| P95 å»¶é² | {report_data.performance_metrics['p95_latency']} ms |
| éŒ¯èª¤ç‡ (4xx/5xx) | {report_data.performance_metrics['error_rate']}% |
| 5xx å³°å€¼æ™‚æ®µ (éå» 24h) | {report_data.performance_metrics['peak_5xx_time']} |

## è³‡æºèˆ‡ä¾è³´

*   **Render æœå‹™ç‹€æ…‹**: {report_data.resource_status['render_status']}
*   **è³‡æ–™åº«é€£ç·šå¥åº·åº¦**:
    *   é€£ç·šæ•¸: {report_data.resource_status['db_connections']}
    *   éŒ¯èª¤æ•¸: {report_data.resource_status['db_errors']}

## ç›£æ§èˆ‡å‘Šè­¦

"""
        
        if report_data.alerts_summary:
            md_content += f"ä»Šæ—¥å…±è§¸ç™¼ {len(report_data.alerts_summary)} å€‹å‘Šè­¦:\n\n"
            for i, alert in enumerate(report_data.alerts_summary, 1):
                md_content += f"{i}. **{alert.get('level', 'UNKNOWN')}**: {alert.get('message', 'No message')}\n"
        else:
            md_content += "ä»Šæ—¥ç„¡å‘Šè­¦äº‹ä»¶ã€‚\n"
        
        md_content += f"""
---

**å ±å‘Šç”Ÿæˆæ™‚é–“**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ•¸æ“šä¾†æº**: 7å¤©è§€å¯ŸæœŸç›£æ§ç³»çµ±
"""
        
        return md_content
    
    def generate_slack_message(self, report_data: DailyReportData) -> Dict:
        """ç”Ÿæˆ Slack è¨Šæ¯æ ¼å¼"""
        # åˆ¤æ–·æ•´é«”ç‹€æ…‹
        health_ok = all(status['success_rate'] > 95 for status in report_data.health_status.values())
        perf_ok = (report_data.performance_metrics['error_rate'] < 1 and 
                  report_data.performance_metrics['p95_latency'] < 500)
        no_alerts = len(report_data.alerts_summary) == 0
        
        if health_ok and perf_ok and no_alerts:
            color = "#36a64f"  # ç¶ è‰²
            status_emoji = "âœ…"
        elif not no_alerts:
            color = "#ff0000"  # ç´…è‰²
            status_emoji = "ğŸš¨"
        else:
            color = "#ffaa00"  # æ©™è‰²
            status_emoji = "âš ï¸"
        
        return {
            "text": f"{status_emoji} æ¯æ—¥ç›£æ§å ±å‘Š - {report_data.date}",
            "attachments": [
                {
                    "color": color,
                    "fields": [
                        {
                            "title": "æœå‹™å¥åº·",
                            "value": f"å¥åº·æª¢æŸ¥: {'âœ… æ­£å¸¸' if health_ok else 'âš ï¸ ç•°å¸¸'}",
                            "short": True
                        },
                        {
                            "title": "æ•ˆèƒ½æŒ‡æ¨™",
                            "value": f"P95: {report_data.performance_metrics['p95_latency']}ms | éŒ¯èª¤ç‡: {report_data.performance_metrics['error_rate']}%",
                            "short": True
                        },
                        {
                            "title": "å‘Šè­¦ç‹€æ³",
                            "value": f"ä»Šæ—¥å‘Šè­¦: {len(report_data.alerts_summary)} å€‹",
                            "short": True
                        },
                        {
                            "title": "æ‘˜è¦",
                            "value": report_data.summary_text.replace('\n', ' | '),
                            "short": False
                        }
                    ],
                    "footer": "7å¤©è§€å¯ŸæœŸç›£æ§ç³»çµ±",
                    "ts": int(datetime.datetime.now().timestamp())
                }
            ]
        }
    
    def generate_report(self, date: str = None) -> DailyReportData:
        """ç”Ÿæˆæ¯æ—¥å ±å‘Š"""
        if date is None:
            date = datetime.datetime.now().strftime('%Y-%m-%d')
        
        # è¼‰å…¥ç›£æ§æ•¸æ“š
        data_date = date.replace('-', '')
        try:
            monitoring_data = self.load_monitoring_data(data_date)
        except FileNotFoundError:
            # å¦‚æœæ²’æœ‰æ•¸æ“šï¼Œå‰µå»ºç©ºå ±å‘Š
            monitoring_data = {'health_results': [], 'daily_report': {}}
        
        health_results = monitoring_data.get('health_results', [])
        
        # åˆ†ææ•¸æ“š
        health_status = self.analyze_health_status(health_results)
        performance_metrics = self.analyze_performance_metrics(health_results)
        resource_status = self.get_resource_status()
        alerts_summary = []  # é€™è£¡å¯ä»¥å¾ç›£æ§æ•¸æ“šä¸­æå–å‘Šè­¦ä¿¡æ¯
        
        # å‰µå»ºå ±å‘Šæ•¸æ“š
        report_data = DailyReportData(
            date=date,
            health_status=health_status,
            performance_metrics=performance_metrics,
            resource_status=resource_status,
            alerts_summary=alerts_summary,
            summary_text=""
        )
        
        # ç”Ÿæˆæ‘˜è¦æ–‡å­—
        report_data.summary_text = self.generate_summary_text(report_data)
        
        return report_data
    
    def save_report(self, report_data: DailyReportData, formats: List[str] = ['markdown', 'json']):
        """å„²å­˜å ±å‘Šåˆ°æ–‡ä»¶"""
        day_num = (datetime.datetime.strptime(report_data.date, '%Y-%m-%d') - 
                  datetime.datetime(2024, 1, 1)).days + 1
        
        base_filename = f"7å¤©è§€å¯ŸæœŸç›£æ§æ—¥èªŒ_Day{day_num}_{report_data.date}"
        
        if 'markdown' in formats:
            md_content = self.generate_markdown_report(report_data)
            md_filename = f"{self.reports_dir}/{base_filename}.md"
            with open(md_filename, 'w', encoding='utf-8') as f:
                f.write(md_content)
            print(f"Markdown report saved: {md_filename}")
        
        if 'json' in formats:
            json_filename = f"{self.reports_dir}/{base_filename}.json"
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump({
                    'date': report_data.date,
                    'health_status': report_data.health_status,
                    'performance_metrics': report_data.performance_metrics,
                    'resource_status': report_data.resource_status,
                    'alerts_summary': report_data.alerts_summary,
                    'summary_text': report_data.summary_text
                }, f, ensure_ascii=False, indent=2)
            print(f"JSON report saved: {json_filename}")
    
    def send_to_slack(self, report_data: DailyReportData, webhook_url: str):
        """ç™¼é€å ±å‘Šåˆ° Slack"""
        message = self.generate_slack_message(report_data)
        
        try:
            response = requests.post(webhook_url, json=message, timeout=10)
            if response.status_code == 200:
                print("Report sent to Slack successfully")
            else:
                print(f"Failed to send report to Slack: {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"Error sending report to Slack: {str(e)}")

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæ¯æ—¥ç›£æ§å ±å‘Š')
    parser.add_argument('--date', help='å ±å‘Šæ—¥æœŸ (YYYY-MM-DD)', default=None)
    parser.add_argument('--slack-webhook', help='Slack Webhook URL', default=None)
    parser.add_argument('--format', choices=['markdown', 'json', 'both'], default='both', help='å ±å‘Šæ ¼å¼')
    
    args = parser.parse_args()
    
    # å¾ç’°å¢ƒè®Šæ•¸ç²å– Slack Webhook
    slack_webhook = args.slack_webhook or os.getenv('SLACK_WEBHOOK_URL')
    
    # å‰µå»ºå ±å‘Šç”Ÿæˆå™¨
    generator = DailyReportGenerator()
    
    try:
        # ç”Ÿæˆå ±å‘Š
        report_data = generator.generate_report(args.date)
        
        # å„²å­˜å ±å‘Š
        formats = ['markdown', 'json'] if args.format == 'both' else [args.format]
        generator.save_report(report_data, formats)
        
        # ç™¼é€åˆ° Slack
        if slack_webhook:
            generator.send_to_slack(report_data, slack_webhook)
        else:
            print("No Slack webhook URL provided, skipping Slack notification")
        
        print(f"Daily report generated successfully for {report_data.date}")
        
    except Exception as e:
        print(f"Error generating report: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())

