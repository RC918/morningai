# MorningAI System Architecture

MorningAI leverages a robust, scalable architecture designed to deliver high-performance code generation, FAQ documentation management, and real-time task orchestration across multiple platforms. This section provides an overview of the core components that make up the MorningAI system architecture.

## Overview

MorningAI's architecture is built to support multi-tenancy and ensure efficient processing of tasks, seamless integration with various messaging platforms, and secure, scalable storage for generated content and vector memory. The system is divided into several key components:

- **Frontend**: Developed with React, utilizing Vite for build optimization and TailwindCSS for styling. This setup ensures a fast, responsive user interface.
  
- **Backend**: The backend logic is powered by Python using the Flask framework, with Gunicorn serving as the WSGI HTTP Server to manage multiple worker processes effectively.

- **Database**: PostgreSQL is used for data storage, enhanced by Supabase for additional features such as Row Level Security (RLS), making data access secure and compliant.

- **Queue**: Redis Queue (RQ) handles task queuing and worker management, providing a reliable mechanism for task execution with worker heartbeat monitoring to ensure health and performance.

- **Orchestration**: LangGraph orchestrates agent workflows, enabling complex processing sequences necessary for autonomous code generation and other AI-driven tasks.

- **AI**: OpenAI's GPT-4 model powers the content generation capabilities of MorningAI, from generating code snippets to creating comprehensive FAQ documents.

- **Deployment**: The platform is deployed on Render.com, benefiting from its CI/CD features for streamlined updates and maintenance.

## System Flow

1. **Request Handling**:
   User requests are received through the frontend interface or via integrated messaging platforms (Telegram, LINE, Messenger). These requests are routed to the appropriate backend service via Flask endpoints.

2. **Task Queuing**:
   For operations requiring asynchronous processing (e.g., code generation), tasks are queued in Redis Queue with specific priorities and are processed by available workers based on their load and capabilities.

3. **Processing**:
   Depending on the task type (e.g., code generation, FAQ creation), LangGraph orchestrates the workflow among different agents. For AI-related tasks, GPT-4 is utilized to generate content based on input parameters and existing data models.

4. **Storage**:
   Generated content is stored in PostgreSQL databases managed by Supabase. Vector memory storage uses pgvector for efficient similarity search operations within the database.

5. **Response Delivery**:
   Once processing is complete, results are sent back to the user through the initial request channel or updated in the frontend application in real-time.

## Configuration Instructions

### Backend Setup

To configure the backend Flask application with Gunicorn:

```bash
cd backend
pip install -r requirements.txt
gunicorn --workers 3 app:app
```

This command starts the Flask application with Gunicorn serving as the HTTP server with 3 worker processes.

### Redis Queue Setup

Ensure Redis is installed and running:

```bash
redis-server
```

Start RQ workers:

```bash
rq worker --with-heartbeat
```

### Database Configuration

Refer to Supabase documentation for setting up PostgreSQL databases with Row Level Security: [Supabase RLS Documentation](https://supabase.io/docs/guides/auth/row-level-security)

## Troubleshooting Tips

- **Worker Not Responding**: Check if Redis server is running and accessible. Review RQ dashboard for any dead or inactive workers.
  
- **Database Connection Issues**: Verify your Supabase credentials and network access rules. Ensure your connection string matches what's specified in your configuration files.
  
- **Deployment Failures on Render.com**: Check build logs for specific errors. Common issues include misconfigured environment variables or failures in dependency installation steps.
  
For more detailed troubleshooting guides and configuration options, refer to our documentation repository: `RC918/morningai/docs/`.

---
Generated by MorningAI Orchestrator using GPT-4

---

**Metadata**:
- Task: What is the system architecture?
- Trace ID: `5af498b6-d63c-4bcf-b524-83c3e4c7bd33`
- Generated by: MorningAI Orchestrator using gpt-4-turbo-preview
- Repository: RC918/morningai
